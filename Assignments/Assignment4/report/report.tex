\documentclass[a4paper]{scrartcl}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{pgfplots}
\usepackage{amsmath, enumerate, amssymb, multirow, fancyhdr, color, graphicx, lastpage, listings, tikz, pdflscape, subfigure, float, polynom, hyperref, tabularx, forloop, geometry, listings, fancybox, tikz, forest, tabstackengine, cancel, algorithm}
\usepackage[noend]{algpseudocode}

\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\input kvmacros
\geometry{a4paper,left=3cm, right=3cm, top=3cm, bottom=3cm}
\pagestyle{fancy}
\title{Assignment 4, Philipp Noel von Bachmann}


\begin{document}
\maketitle

\section{Problem}
    In the N-body Problem, we want to predict the movement of n bodies that
    interact with each other over time. The interaction is given by the force
    they excert on each other, which in turn changes the acceleration of each
    body, thus the velocity and position. The problem is modeled by assuming
    pairwise interaction between the bodies and taking their sum as the total
    force excerted onto each body.

    In this exercise, we use an algorithm known as the Barnes-Hut. This
    algorithm reduces the computational cost by approximating a group of starts
    that are far away as one single big star. Together with a representation
    known as a quad-tree, this enables us to reduce the computational complexity
    significantly.

\section{Solution}
    \subsection{Data structure}
        \subsubsection{Body}
            Like in the previous assignment, we have the following 4 characteristics of each body:
            \begin{itemize}
                \item velocity
                \item position
                \item mass
                \item brightness
            \end{itemize}
            Mass and brightness are represented as double, since they are both
            continuous. As position and velocity are both vectors, they are
            represented as a struct of coordinates. Since we model the problem in
            2D, each vector thus comprises of an x and y coordinate. The
            characteristics are collected in a struct called body. This format
            also allows for easy reading of the input gal file, since we can
            directly read each block into a body struct.

            We also need to keep track of the accelerations of each body in an
            array of coordinates. We opt not to integrate this into the body
            struct to be able to retain easy writing and reading of .gal files.

        \subsubsection{Quadtree}
            A quadtree is a tree of nodes, where every node represents a subset
            of an area of interest. Each node can be either an internal or external node.

            An external node is a node whose area contains only one body. If the
            area contains more than one body, the node is called an internal
            node. Instead of having an body that belongs to this node, the node
            has 4 child nodes which represent the 4 subareas. To construct a
            quadtree, we therefore split all nodes recursively until each leaf
            node is an external node. A node whose area contains no bodies is
            also considered a external node.

            In general, we represent a node in a structure with the following attributes:
            \begin{itemize}
                \item lower: coordinate representing the lower edge of the area covered by the node
                \item upper: coordinate representing the upper edge of the area covered by the node
                \item children: A list containing a pointer to each of the children nodes if there are any, else a NULL pointer.
                \item body: A pointer to the body contained by this node if an external node, else a NULL pointer.
                \item total mass: A float representing the total mass of the bodies in the area of this node.
                \item center of mass: A coordinate, representing the center of all bodies contained by this node weighted by their mass.
            \end{itemize}

    \subsection{Overview of Algorithm}
        In general, we have the following three steps of our main function:
        \begin{itemize}
            \item Load the data
            \item Perform the simulation
            \item Safe the output data
        \end{itemize}
        The main part is the simulation, which is done by recursively calling
        the step function which progresses the simulation by one timestep.
        \begin{algorithm}[H]
            \caption{One environment step}\label{alg:step}
            \begin{algorithmic}[1]
            \Procedure{Step}{}
            \For{each body in all bodies}
            \State force = \Call{compute\_force}{body, tree}
            \EndFor
            \For{each body in all bodies}
            \State update the position of that body
            \EndFor
            \State replace the old quadtree by a new empty one
            \For{each body in all bodies}
            \State Insert the body in the new quadtree
            \EndFor
            \EndProcedure
            \end{algorithmic}
        \end{algorithm}
        A crucial aspect is that we need to perform all force computations
        before we update the positions of our body, which will especially become
        important later for parallelization. In our initial implementation, we
        stick to rebuilding the quadtree after each step, instead of updating
        it. See also Section \ref{sec:Runtime} for how this affects the runtime.
        
        The force is computed by descending the quadtree:
        \begin{algorithm}[H]
            \caption{Force computation}\label{alg:compute_force}
            \begin{algorithmic}[1]
            \Procedure{compute\_force}{body, current node}
            \If {current node is external}
                \State force = force between body and body of external node
            \Else      
                \For{child in children of current node}
                    \If{child is empty}
                        \State continue
                    \EndIf
                    \If {child is far enough away}\label{alg:line6}
                        \State force += force between body and a big body at center of child
                    \Else { need to descent into that child}
                        \State force += \Call{compute\_force}{body, child}
                    \EndIf
            \EndFor
            \EndIf
            \State \Return force
            \EndProcedure
            \end{algorithmic}
        \end{algorithm}
        Here, we safe the most amount of time compared to the naive algorithm
        from Assignment 3 in line \ref{alg:line6}, where we treat all bodies in the child as
        one big one and thus don`t need to descent into that child.


\section{Performance and Discussion for Serial code}
    \subsection{Hardware information}
        \begin{itemize}
            \item CPU: Apple M1 with 4 performance cores and 4 efficiency cores
            \item GPU: Apple M1 8 core.
            \item Compiler: Slang, Version 13.0.0
            \item Plugged into power adapter, this makes a big difference!
        \end{itemize}

    \subsection{Performance Measurement script}
        The performance was measured with shell scripts to enable
        reproducability. The script mostly loops over the parameters of interest
        and computes the respective runtime. In the end we also check that the
        code is correct with the \textbf{compare\_gals} file. Our time
        measurement was done within the c code with the help of the time
        \textbf{timeoftheday} function. We started the time measurement after
        the data loading and stopped the measurement before data writing.


    \subsection{Calculation of $\theta_{\max}$}
        
        We calculate $\theta_{\max}$ as described in the Assignment, Section
        5.2. This results in $\theta_{\max} = 0.25$, where an
        $\text{\textbf{pos\_maxdiff}} = 0.000885759450$ was achieved.
    \subsection{Results}
        \subsubsection{Baseline}\label{sec:Baseline}
            The following graph shows the results of the algorithm with no
            optimization for a variable number of bodies, always using 100 steps:

            \begin{tikzpicture}[scale=0.7]
                \begin{axis}[
                    xmin = 10, xmax = 5000,
                    ymin = 0, ymax = 13.0,
                    xtick distance = 1000,
                    ytick distance = 1,
                    grid = both,
                    minor tick num = 1,
                    major grid style = {lightgray},
                    minor grid style = {lightgray!25},
                    width = 0.8\textwidth,
                    height = 0.8\textwidth,
                    xlabel = {Number of bodies},
                    ylabel = {Time (s)},]
                 
                 
                % Plot data from a file
                \addplot[
                    scatter,
                    thin,
                    red,
                    dashed
                ] file[skip first] {results.dat};
                 
                \end{axis}
                 
            \end{tikzpicture}
            

            Compared to the last assignment, these result are far quicker than
            the last assignment, for example for N=1000 we achieve 1.491261s
            compared to 6.502 in the last assignment. For large N, we see that
            the runtime becomes nearly linear.

        \subsubsection{Analysis of runtime}\label{sec:Runtime}
            This section analyzes the runtime of the two main parts of algorithm
            \ref{alg:step}:
            \begin{itemize}
                \item Tree: For the Barnes-Hut, we need to build and update the tree after each timestep.
                \item Body update: For each step, we need to update the forces and the body positions etc.
            \end{itemize}
            \noindent\begin{tabular}{c|c|c|c}
                N bodies & 10 & 100 & 1000 \\
                \hline
                Tree time (s) & 0.0003 & 0.003 & 0.042 \\
                Body update time (s) & 0.001 & 0.045 & 1.449\\
            \end{tabular}\\[10pt]
            We see that we spend most of the time on computing the update steps
            for the bodies and a negligible amount of time on the rebuilding of
            the tree. Therefore, we decide not to optimize the tree further by
            for example updating the tree instead of rebuilding, since the
            possible time to gain is very little. Instead we will focus on
            optimizing the force computation and position update of our body.

        \subsubsection{Inplace computation}
            In the baseline algorithm \ref{alg:compute_force}, we compute the
            force recursively if we need to descent into the children. However,
            this creates a lot of unneeded force objects, that we need to
            recursively pass around. Instead, we can just add the force to a
            global array of forces which gets initialized to 0 at the beginning
            of every step.
            \begin{algorithm}[H]
                \caption{Force computation, assuming global array force\_arr initialized to 0}\label{alg:compute_force_inplace}
                \begin{algorithmic}[1]
                \Procedure{compute\_force\_Inplace}{body, current node}
                \If {current node is external}
                    \State force\_arr[body] += force between body and body of external node
                \Else      
                    \For{child in children of current node}
                        \If {child is far enough away}
                            \State force\_arr[body] += force between body and a big body at center of child
                        \Else { need to descent into that child}
                            \State \Call{compute\_force\_inplace}{body, child}
                        \EndIf
                \EndFor
                \EndIf
                \EndProcedure
                \end{algorithmic}
            \end{algorithm}
            This leads to the following results:\\
            \noindent\begin{tabular}{c|c|c|c}
                N bodies & 10 & 100 & 1000 \\
                \hline
                time (s) & 0.0003 & 0.004 & 1.117\\
            \end{tabular}\\
            We see that for $N=1000$, this reduces the computation time from
            1.491261s to 1.117s.

        \subsubsection{Early stopping}
            In a setup where we have a lot of distant bodies, the quadtree
            representation might be quite spare in the sense that we have a lof
            of emtpy nodes. Therefore, one idea is that at a minimum amount of
            nodes in that subtree, instead of descending that tree we just
            compute the naive update from Assignment 3 with all the bodies in
            that subtree. This would remove iterating over a lot of empty nodes
            and performing a lot of checks. Table \ref{tab:early} shows the
            results for 1000 bodies and 100 steps:\\[10pt] 
            \noindent\begin{tabular}{c|c|c|c}\label{tab:early}
                minimum N bodies & 0 (baseline) & 5 & 10 \\
                \hline
                time (s) & 1.119 & 1.370 & 1.704\\
            \end{tabular}\\

            We don't get the expected result, instead we see that our time
            increases. One reason might be that while there are a lot of empty
            nodes which take time iterating over and a lot of checks to
            determine if we need to descent into that child, these checks also
            gain time by not needing to descent into these childs. In total,
            this saves time. Therefore, we decide not to include this
            modification in the rest of the optimizations.
            

        \subsubsection{Memory usage}
            The quadtree for large galaxies will not fit into one cacheline, and
            we spend a lot of time loading new bodies in our memory. Therefore,
            the idea is to instead of updating each body in serial, load a
            subtree into the memory and then perform the force computation with
            that subtree for all bodies, and iterate over a number of subtrees.

            \begin{algorithm}[H]
                \caption{One environment step with subtree update}
                \begin{algorithmic}[1]
                \Procedure{Step}{}
                \State subtree\_list = list of nodes at a certain level of tree
                \For{subtree in subtree\_list}
                    \For{each body in all bodies}
                    \State force += \Call{compute\_force}{body, subtree}
                    \EndFor
                \EndFor
                \For{each body in all bodies}
                \State update the position of that body
                \EndFor
                \State replace the old quadtree by a new empty oen
                \For{each body in all bodies}
                \State Insert the body in the new quadtree
                \EndFor
                \EndProcedure
                \end{algorithmic}
            \end{algorithm}
            We investigate the runtime wrt the level we descent to build the
            subtree. Descending further down might lower the memory usage and
            therefore be more likely to fit in one cacheline on the one hand,
            but remove the chance to prune the tree earlier by approximating
            bodies as one big body. The results are shown for 1000 bodies and
            100 steps.\\

            \noindent\begin{tabular}{c|c|c|c|c|c|c|c}
                N levels & 0 (base) & 1 & 2 & 3 & 4 & 5 & 10 \\
                \hline
                time (s) &  1.146 & 1.074 & 1.049 & 1.028 & 1.011 & 1.173 & 2.671\\
            \end{tabular}\\

            We see that in the best case, this speeds up computation by 0.13s
            for a level of 4. However as we further increase the level, we can't
            prune subtrees anymore and loose time again. In the end, we
            therefore fix the level at 4.

        \subsubsection{Optimization flags}
            Finally, we use optimization flags to optimize the code further, as
            before results are shown for 1000 bodies and 100 steps.\\
            \noindent\begin{tabular}{c|c|c|c}
                 & No flags & -O2 & -O3 \\
                \hline
                time (s) & 1.022 & 0.337 & 0.325\\ 
            \end{tabular}\\
            We see that we achieve the best performance using -O3, therefore we
            use that option from now on.

    \subsection{Final code evaluation}
        The figure shows the results for the final code for 100 timesteps
        and a variable number of bodies.
        \begin{tikzpicture}[scale=0.7]
            \begin{axis}[
                xmin = 10, xmax = 5000,
                ymin = 0, ymax = 3,
                xtick distance = 1000,
                ytick distance = 1,
                grid = both,
                minor tick num = 1,
                major grid style = {lightgray},
                minor grid style = {lightgray!25},
                width = 0.8\textwidth,
                height = 0.8\textwidth,
                xlabel = {Number of bodies},
                ylabel = {Time (s)},]
            
            
            % Plot data from a file
            \addplot[
                scatter,
                thin,
                red,
                dashed
            ] file[skip first] {results_final.dat};
            
            \end{axis}
        \end{tikzpicture}

    We can see that for a large number of bodies, the runtime becomes nearly
    linear. This is much better than $O(n^2)$ in Assignment 3. 

\section{Parallel implementation}



    \subsection{Assignment 4}
        \subsubsection{Code}
            If we look through the pseudo-code \ref{alg:step} we see that the
            force computation of each body is independent of all the other
            bodies. However we noted further, that we can only start updating
            the postion after we computed all the forces, otherwise we would get
            incorrect results. Therefore, we modify the main loop to:
            \begin{algorithm}[H]
                \caption{One environment step with parallel updates}\label{alg:stepparallel}
                \begin{algorithmic}[1]
                    \Procedure{Step}{}
                    \For{thread in threads}
                    \State Call thread with \Call {compute\_force\_parallel}{start, end (for this thread)}
                    \EndFor
                    \For{thread in threads}
                    \State \Call {join}{thread}
                    \EndFor
                    \For{each body in all bodies}
                    \State update the position of that body
                    \EndFor
                    \State replace the old quadtree by a new empty oen
                    \For{each body in all bodies}
                    \State Insert the body in the new quadtree
                    \EndFor
                    \EndProcedure
                \end{algorithmic}
            \end{algorithm}
            and add the method:
            \begin{algorithm}[H]
                \caption{Force computation done by one thread}
                \begin{algorithmic}[1]
                    \Procedure{Compute\_force\_parallel}{start, end}
                    \For{each body in all bodies between start and end}
                        \State force = \Call{compute\_force}{body, tree}
                    \EndFor
                    \EndProcedure
                \end{algorithmic}
            \end{algorithm}
            Here, we divide the task between threads by giving each thread just
            a subset of bodies to update. As noted, we have to join the thread
            before we update our position. An alternative would be to use a
            barrier so that all threads wait until the others are finished
            computing the force, and then update the position in parallel. Note
            that for simplicity we only show the easy pseudo-code here, however
            all optimizations from the previous section like inplace computation
            and memory-optimization were also applied.

        \subsubsection{Results}
            The figure shows the speedup with the number of threads for 1000
            bodies and 100 steps.
            \begin{tikzpicture}[scale=0.7]
                \begin{axis}[
                    xmin = 1, xmax = 20,
                    ymin = 0.1, ymax = 0.35,
                    xtick distance = 1,
                    ytick distance = 0.01,
                    grid = both,
                    minor tick num = 1,
                    major grid style = {lightgray},
                    minor grid style = {lightgray!25},
                    width = 0.8\textwidth,
                    height = 0.8\textwidth,
                    xlabel = {Number of bodies},
                    ylabel = {Time (s)},]
                
                
                % Plot data from a file
                \addplot[
                    scatter,
                    thin,
                    red,
                    dashed
                ] file[skip first] {results_A4_parallel.dat};
                \end{axis}
            \end{tikzpicture}

        We can see that initally using more threads decrease our time nearly
        linear: For 1 thread we get a time of 0.33s and for 2 0.19s. However as
        we progress further, this increase flattens significantly until at
        around 8 threads, we come to a stop of increase, which makes sense
        considering the machine used has 8 cores. Interestingly, we don't get a
        linear decrease until 8 cores, as one would expect, rather we get an
        bump at 5 cores. One reason might be the architecture of the
        machine - The M1 Mac has 4 high performance and 4 efficiency cores, so
        the high performance cores probably have to wait for the efficiency
        cores to finish.

        We also found that using a barrier or updating the positions in
        sequence after the join doesn't matter. This is probably because the
        operation first of all has linear time complexity and second is very
        cheap, since we mostly just need to write values to an array.

    \subsection{Assignment 3}
        \subsubsection{Code}
            Recall the algorithm for assignment 3:
            \begin{algorithm}[H]
                \caption{One environment step, Assignment 3}
                \begin{algorithmic}[1]
                \Procedure{Step}{}
                \For{each body in all bodies}
                    \For{each second body in all bodies}
                        \State force[body] += \Call{compute\_force}{body, second body}
                    \EndFor
                \EndFor
                \For{each body in all bodies}
                \State update the position of that body
                \EndFor
                \EndProcedure
                \end{algorithmic}
            \end{algorithm}

            Here, we see that we can parallelize the force computation step. However
            we need to wait with the update step, since otherwise force
            computations can be wrong. This is either achieved by calling join
            before the update and then updating in serial or implementing a
            barrier which lets all threads wait for the others to complete
            before the update, similar to Assignment 4.

        \subsubsection{Results}
            The figure shows the speedup with the number of threads for 1000
            bodies and 100 steps.
            \begin{tikzpicture}[scale=0.7]
                \begin{axis}[
                    xmin = 1, xmax = 20,
                    ymin = 0.01, ymax = 0.2,
                    xtick distance = 1,
                    ytick distance = 0.01,
                    grid = both,
                    minor tick num = 1,
                    major grid style = {lightgray},
                    minor grid style = {lightgray!25},
                    width = 0.8\textwidth,
                    height = 0.8\textwidth,
                    xlabel = {Number of bodies},
                    ylabel = {Time (s)},]
                
                
                % Plot data from a file
                \addplot[
                    scatter,
                    thin,
                    red,
                    dashed
                ] file[skip first] {results_A3_parallel.dat};
                \end{axis}
            \end{tikzpicture}

            We see the same pattern as in Assignment 4, when going over 4 cores
            our runtime rises again due to the same reasons. In general, we see
            that we surprisingly achieve a lower runtime however. This could be
            because we use mostly standard functions, thus making it easier for
            the compiler to do optimizations.



            

\section{References}
    \begin{itemize}
        \item For the timing, the \textbf{get\_wall\_seconds} from Lab06, exercise 7
        \item For data reading, the function \textbf{read\_doubles\_from\_file} from \textbf{compare\_gal\_files}, but slightly modified
        \item For the barrier, the code from Lab09, exercise 4
        \item For the parallel assignment 3, the code from Assignment 3
        \item To get more familar with the Barnes-Hut, the explanation from
        \url{https://www.cs.princeton.edu/courses/archive/fall03/cs126/assignments/barnes-hut.html},
        however no parts of the code.
    \end{itemize}



\end{document}

